#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\use_default_options true
\begin_modules
knitr
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 3cm
\topmargin 2.54cm
\rightmargin 3cm
\bottommargin 2.54cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
STAT243 Problem Set 7
\end_layout

\begin_layout Author
Name: Chih Hui Wang SID: 26955255
\end_layout

\begin_layout Date
November 2, 2015
\end_layout

\begin_layout Section*
1.
\end_layout

\begin_layout Itemize

\series bold
What are the goals of their simulation study and what are the metrics that
 they consider in assessing their method?
\end_layout

\begin_layout Standard
The goals of the simulation study are to evaluate the accuracy of their
 proposed asymptotic approximation in finite samples and to examine the
 power of their EM test.
\end_layout

\begin_layout Itemize

\series bold
What choices did the authors have to make in designing their simulation
 study? What are the key aspects of the data generating mechanism that likely
 affect the statistical power of the test?
\end_layout

\begin_layout Standard
When they design their simulation study, they have to decide 
\begin_inset Formula $\theta$
\end_inset

 and 
\begin_inset Formula $\sigma$
\end_inset

 for the mixture normal models.
 Also, they calculated the test statistic based on their recommendation
 for β and K as well as the two penalty functions 
\begin_inset Formula $p(\beta)$
\end_inset

 and 
\begin_inset Formula $p(\sigma^{2},\hat{{\sigma}}^{2})$
\end_inset

.
 If the choice of 
\begin_inset Formula $\theta$
\end_inset

 and 
\begin_inset Formula $\sigma$
\end_inset

 was inappropriate, it would affect power of the test.
 For example, if we pick 
\begin_inset Formula $\theta_{1}$
\end_inset

 and 
\begin_inset Formula $\theta_{2}$
\end_inset

 which were too closed to each other, we cannot distinguish the two groups,
 which indicated the existence of dominance group.
\end_layout

\begin_layout Itemize

\series bold
Suggest some alternatives to how the authors designed their study.
 Are there data-generating scenarios that they did not consider that would
 be useful to consider?
\end_layout

\begin_layout Standard
They can consider the scenarios that the null order is 1 and compare it
 with alternative order bigger than one.
\end_layout

\begin_layout Itemize

\series bold
Give some thoughts on how to set up a simulation study for their problem
 that uses principles of basic experimental design (see the Unit 10 notes)
 or if you think it would be difficult, say why.
\end_layout

\begin_layout Standard
The part for generating random number from mixture normal distribution will
 not be too difficult.
 For two mixture normal, we can do by generating random number from two
 normal distributions.
 After that, we create another random number with value 0s and 1s to decide
 the ith observation is from which normal distribution.
 The proportion of 0s in the random number is 
\begin_inset Formula $\alpha_{1}$
\end_inset

 while the proportion of 1s is 
\begin_inset Formula $\alpha_{2}$
\end_inset

.
 The difficult part of the simulation study is to choose the appropriate
 sample size, replication number, parameters of normal distribution.
\end_layout

\begin_layout Itemize

\series bold
Do their figures/tables do a good job of presenting the simulation results
 and do you have any alternative suggestions for how to do this? Do the
 authors address the issue of simulation uncertainty/simulation standard
 errors and/or do they convince the reader they've done enough simulation
 replications?
\end_layout

\begin_layout Standard
I do not think that their figures/tables give a very clear summary about
 their simulation study.
 They have set up 12 null models with order 2, used them to calculate the
 Type I error based on 5000 replications and summarized by boxplot.
 However, I wondered why there is only 1 boxplot for each scenario (different
 sample sizes and significant levels).
 Are there supposed to have boxplot to summarize each null model? The same
 things happened when computing powers.
 They give table to summarize the power under different scenarios (different
 sample size, numbers of iteration, combinations of alternative 
\begin_inset Formula $\theta$
\end_inset

 and 
\begin_inset Formula $\sigma$
\end_inset

, weights) while I think that powers would be different among different
 null model, so perhaps there should be several tables to present the result.
 For the uncertainty, it seems that they did not reveal any information
 about it.
 For the choice of replications such as 5000 replications for calculating
 Type I error and 1000 replications for calculating power, they did not
 explain the reason why they chose the number too.
\end_layout

\begin_layout Itemize

\series bold
Interpret their tables on power (Tables 4 and 6) - do the results make sense
 in terms of how the power varies as a function of the data generating mechanism
?
\end_layout

\begin_layout Standard
The results make sense.
 The power increases as the sample size increases.
 Also, when the alternative models become far away from one another, the
 power increases.
 Finally, the number of iteration increases, the power increases while not
 dramatically.
\end_layout

\begin_layout Itemize

\series bold
Discuss the extent to which they follow JASA's guidelines on simulation
 studies (see the end of the Unit 10 class notes for the JASA guidelines).
\end_layout

\begin_layout Standard
Overall, they follow the JASA’s guidelines such as algorithm, programming
 language and major software components that were used.
 However, the part for estimated accuracy of results and descriptions of
 pseudorandom-number generators are not so clear when I browse through the
 paper.
 For example, it did not show that how they generate the data and some uncertain
 measures such as standard error.
 
\end_layout

\begin_layout Section*
2.
\end_layout

\begin_layout Standard
(a) Below are the steps for the Cholesky decomposition:
\end_layout

\begin_layout Enumerate
\begin_inset Formula $U_{11}=\sqrt{A_{11}}$
\end_inset


\end_layout

\begin_layout Enumerate
For 
\begin_inset Formula $j=2,\ldots,n$
\end_inset

, 
\begin_inset Formula $U_{1j}=A_{1j}/U_{11}$
\end_inset

 
\series bold

\begin_inset Formula $\lbrace n-1\rbrace$
\end_inset


\end_layout

\begin_layout Enumerate
For 
\begin_inset Formula $i=2,\ldots,n$
\end_inset

, 
\end_layout

\begin_layout Itemize
\begin_inset Formula $U_{ii}=\sqrt{A_{ii}-\sum_{k=1}^{i-1}U_{ki}^{2}}$
\end_inset

 
\begin_inset Formula $\lbrace(1+2+\cdots+(n-1)=\dfrac{n(n-1)}{2}\rbrace$
\end_inset


\end_layout

\begin_layout Itemize
for 
\begin_inset Formula $j=i+1,\ldots,n$
\end_inset

: 
\begin_inset Formula $U_{ij}=(A_{ij}-\sum_{k=1}^{i-1}U_{ki}U_{kj})/U_{ii}$
\end_inset

 
\begin_inset Formula $\lbrace\sum_{i=2}^{n}(n-i)i=\sum_{i=2}^{n}ni-i^{2}=\dfrac{n^{3}-7n+6}{6}\rbrace$
\end_inset


\end_layout

\begin_layout Standard
Hence, the total steps is 
\begin_inset Formula $(n-1)+\dfrac{n(n-1)}{2}+\dfrac{n^{3}-7n+6}{6}=\dfrac{n^{3}+3n^{2}-4n}{6}.$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\]

\end_inset


\end_layout

\begin_layout Standard
(b) No, we will not overwrite the value we need for calculation when we
 do the calculation and store the elements of 
\begin_inset Formula $U$
\end_inset

 at the same time.
 As above steps indicated, we easily tell that the step 1 and 2 can be calculate
d and stored at the same time.
 For the step 3, when we calculate the term 
\begin_inset Formula $U_{ii}$
\end_inset

, we are using the elements above 
\begin_inset Formula $U_{ii}$
\end_inset

 which will be calculated first.
 When we calculate the term 
\begin_inset Formula $U_{ij}$
\end_inset

, we are using 
\begin_inset Formula $U_{ii}$
\end_inset

 and the elements above 
\begin_inset Formula $U_{ij}$
\end_inset

 and 
\begin_inset Formula $U_{ii}$
\end_inset

.
 All of them will be calculated before we compute 
\begin_inset Formula $U_{ij}$
\end_inset

.
 Therefore, we can do the calculation and store the outcomes in the original
 matrix without using additional memory.
\end_layout

\begin_layout Standard
(c) From the results of 
\series bold
mem_used
\series default
 and 
\series bold
gc
\series default
, we can see that there is 7.6 MB memory used temporarily when R do the Cholesky
 decomposition.
 It will be clean soon after R finished the computation.
 Therefore, when doing the Cholesky decomposition, R make a copy of the
 original matrix and do the Cholesky decomposition.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<memory>>=
\end_layout

\begin_layout Plain Layout

n <- 1000
\end_layout

\begin_layout Plain Layout

X <- crossprod(matrix(rnorm(n^2), n))
\end_layout

\begin_layout Plain Layout

gc(reset=TRUE)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

library(pryr)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<chol>>=
\end_layout

\begin_layout Plain Layout

mem_used()
\end_layout

\begin_layout Plain Layout

gc()
\end_layout

\begin_layout Plain Layout

invisible(chol(X))
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<temporary>>=
\end_layout

\begin_layout Plain Layout

gc()
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The graph indicated that both processing time and memory use are cubic to
 n.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<timescale, fig.align='center', fig.height=3.5, fig.width=7>>=
\end_layout

\begin_layout Plain Layout

#Reset
\end_layout

\begin_layout Plain Layout

gc(reset=TRUE)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

n <- seq(1000, 5000, by=1000) 
\end_layout

\begin_layout Plain Layout

record <- function(n){
\end_layout

\begin_layout Plain Layout

  X <- crossprod(matrix(rnorm(n^2), n))
\end_layout

\begin_layout Plain Layout

  time <- rep(0, 2)
\end_layout

\begin_layout Plain Layout

  
\end_layout

\begin_layout Plain Layout

  #Get the processing time(elapsed)
\end_layout

\begin_layout Plain Layout

  time[1] <- system.time(U <- chol(X))[3]
\end_layout

\begin_layout Plain Layout

  
\end_layout

\begin_layout Plain Layout

  #Get the maximum memory for Vcells
\end_layout

\begin_layout Plain Layout

  time[2] <- gc()[2, 5]
\end_layout

\begin_layout Plain Layout

  
\end_layout

\begin_layout Plain Layout

  time
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

result <- t(sapply(n, record))
\end_layout

\begin_layout Plain Layout

result <- as.data.frame(cbind(n, result))
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Change the variable name
\end_layout

\begin_layout Plain Layout

names(result) <- c("n", "time", "memory")
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

library(ggplot2); library(gridExtra)
\end_layout

\begin_layout Plain Layout

#Plot
\end_layout

\begin_layout Plain Layout

grid.arrange(
\end_layout

\begin_layout Plain Layout

  ggplot(result, aes(x=n, y=time)) + geom_line(),
\end_layout

\begin_layout Plain Layout

  ggplot(result, aes(x=n, y=memory)) + geom_line(),
\end_layout

\begin_layout Plain Layout

  ncol=2
\end_layout

\begin_layout Plain Layout

)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Section*
3.
\end_layout

\begin_layout Standard
(a) 
\series bold
solve
\series default
 in R use the LU decomposition and then backsolve to get the value.
 The order of computations for full inversion is 
\begin_inset Formula $n^{3}.$
\end_inset

 Therefore, in (a), the order should be 
\begin_inset Formula $n^{3}+O(n^{2})$
\end_inset

 where 
\begin_inset Formula $n^{2}$
\end_inset

 is the time for multiplication.
 In (b), the order of computations for LU decomposition is 
\begin_inset Formula $\dfrac{n^{3}}{3}+O(n^{2})$
\end_inset

.
 In (c), we use Cholesky decomposition and backsolve which should take around
 
\begin_inset Formula $\dfrac{n^{3}}{6}+O(n^{2})$
\end_inset

 computation order.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<setup>>=
\end_layout

\begin_layout Plain Layout

set.seed(0)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Set-up
\end_layout

\begin_layout Plain Layout

n <- 5000
\end_layout

\begin_layout Plain Layout

X <- crossprod(matrix(rnorm(n^2), n))
\end_layout

\begin_layout Plain Layout

y <- as.matrix(rnorm(n))
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<first>>=
\end_layout

\begin_layout Plain Layout

#First approach
\end_layout

\begin_layout Plain Layout

system.time(b1 <- solve(X) %*% y)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<second>>=
\end_layout

\begin_layout Plain Layout

#Second approach
\end_layout

\begin_layout Plain Layout

system.time(b2 <- solve(X, y))
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<third>>=
\end_layout

\begin_layout Plain Layout

#Third approach
\end_layout

\begin_layout Plain Layout

approach3 <- function(X, y){
\end_layout

\begin_layout Plain Layout

  U <- chol(X)
\end_layout

\begin_layout Plain Layout

  b <- backsolve(U, backsolve(U, y, transpose=TRUE))
\end_layout

\begin_layout Plain Layout

  b
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

system.time(b3 <- approach3(X, y))
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
(b) We can find that the results of these three methods are 7 digits in
 agree.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<result>>=
\end_layout

\begin_layout Plain Layout

#print out 22 number after decimal point
\end_layout

\begin_layout Plain Layout

options(digits=22)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Transpose the result for comparison
\end_layout

\begin_layout Plain Layout

t(cbind(head(b1, n=3), head(b2, n=3), head(b3, n=3)))
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The conditional number of matrix 
\begin_inset Formula $X$
\end_inset

 is around 
\begin_inset Formula $10^{7}$
\end_inset

 which implies that we will have accuracy of order 
\begin_inset Formula $10^{9}$
\end_inset

.
 It is the same as the results above indicated.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<eigen_value>>=
\end_layout

\begin_layout Plain Layout

#Get back to default
\end_layout

\begin_layout Plain Layout

options(digits=7)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Eigenvalues
\end_layout

\begin_layout Plain Layout

v <- eigen(X)$values
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#condition number
\end_layout

\begin_layout Plain Layout

v[1]/v[length(v)]
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Section*
4.
\end_layout

\begin_layout Standard
My strategy is to try make the form back to 
\begin_inset Formula $X^{T}X\beta=X^{T}Y$
\end_inset

.
 By doing so, we can apply the QR decomposition and backsolve to get the
 solution, which takes 
\begin_inset Formula $2np^{2}-\dfrac{2}{3}p^{3}$
\end_inset

.
 Therefore, I first start with decomposition for 
\begin_inset Formula $\Sigma^{-1}$
\end_inset

.
 I use Cholesky decomposition, 
\begin_inset Formula $\Sigma=U^{T}U$
\end_inset

, which takes 
\begin_inset Formula $\dfrac{n^{3}}{6}+O(n^{2})$
\end_inset

.
 
\begin_inset Formula 
\begin{eqnarray*}
X^{T}\Sigma^{-1}X{}^{-1}\beta & = & X^{T}\Sigma^{-1}Y\\
\Rightarrow X^{T}(U^{T}U)^{-1}X\beta & = & X^{T}(U^{T}U)^{-1}Y\\
\Rightarrow X^{T}U^{-1}(U^{T})^{-1}X\beta & = & X^{T}U^{-1}(U^{T})^{-1}Y\\
 & \mbox{}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $(U^{T})^{-1}X=X^{*}$
\end_inset

 (takes 
\begin_inset Formula $n^{3}$
\end_inset

)and 
\begin_inset Formula $(U^{T})^{-1}Y=Y^{*}$
\end_inset

(takes 
\begin_inset Formula $n^{2}$
\end_inset

), then the above equation can be rewritten into
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
(X^{*})^{T}X^{*}\beta=(X^{*})^{T}Y^{*}
\]

\end_inset


\end_layout

\begin_layout Standard
whick is back to the form we familiar with.
 Now we can use QR decomposition for 
\begin_inset Formula $X^{*}$
\end_inset

 and solve the 
\begin_inset Formula $\beta$
\end_inset

 by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
R^{*}\beta=(Q^{*})^{T}Y
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $X^{*}=Q^{*}R^{*}.$
\end_inset

 The psesudo-cdoe and the order of computations for doing this are: 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<psesudocode, eval=FALSE>>=
\end_layout

\begin_layout Plain Layout

gls <- function(X, Sigma, y)
\end_layout

\begin_layout Plain Layout

  U <- cholesky(Sigma)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

  U_inv <- inverse(U)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

  newX <- transpose(U_inv) %*% X
\end_layout

\begin_layout Plain Layout

  newY <- transpose(U_inv) %*% Y
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

  Q <- QR(newX)
\end_layout

\begin_layout Plain Layout

  R <- QR(newX)$R
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

  b <- backsolve(R, transpose(Q) %*% newY)
\end_layout

\begin_layout Plain Layout

  b
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The following is the R code and a example to run the function.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<gls>>=
\end_layout

\begin_layout Plain Layout

gls <- function(X, Sigma, y){
\end_layout

\begin_layout Plain Layout

  #Cholesky decomposition of Sigma
\end_layout

\begin_layout Plain Layout

  U <- chol(Sigma)
\end_layout

\begin_layout Plain Layout

  
\end_layout

\begin_layout Plain Layout

  #Compute the new X matrix and y vector
\end_layout

\begin_layout Plain Layout

  UT_inv <- t(solve(U))
\end_layout

\begin_layout Plain Layout

  newX <- UT_inv %*% X
\end_layout

\begin_layout Plain Layout

  newy <- UT_inv %*% y
\end_layout

\begin_layout Plain Layout

  
\end_layout

\begin_layout Plain Layout

  #Do the QR decomposition
\end_layout

\begin_layout Plain Layout

  qrX <- qr(newX)
\end_layout

\begin_layout Plain Layout

  
\end_layout

\begin_layout Plain Layout

  #Q and R matrix
\end_layout

\begin_layout Plain Layout

  Q <- qr.Q(qrX); R <- qr.R(qrX)
\end_layout

\begin_layout Plain Layout

  
\end_layout

\begin_layout Plain Layout

  #Solve the equation
\end_layout

\begin_layout Plain Layout

  b <- backsolve(R, t(Q) %*% newy)
\end_layout

\begin_layout Plain Layout

  b
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<example, fig.align='center', fig.height=3.5, fig.width=3.5>>=
\end_layout

\begin_layout Plain Layout

#Setup
\end_layout

\begin_layout Plain Layout

n <- 3000
\end_layout

\begin_layout Plain Layout

p <- 100
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

X <- matrix(rnorm(n*p), ncol=p)
\end_layout

\begin_layout Plain Layout

Sigma <- crossprod(matrix(runif(n^2), n))
\end_layout

\begin_layout Plain Layout

Y <- rnorm(n)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

system.time(beta <- gls(X, Sigma, Y))
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Predicted value
\end_layout

\begin_layout Plain Layout

Yhat <- X %*% beta
\end_layout

\begin_layout Plain Layout

plot(Y, Yhat)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Section*
5.
\end_layout

\begin_layout Standard
(a) 
\begin_inset Formula $1^{\circ}$
\end_inset

 Right singular vectors of 
\begin_inset Formula $X$
\end_inset

 are the eigenvectors of the matrix 
\begin_inset Formula $X^{T}X$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula $2^{\circ}$
\end_inset

 The eigenvalues of 
\begin_inset Formula $X^{T}X$
\end_inset

 are the squares of the singular values of 
\begin_inset Formula $X$
\end_inset

.
\end_layout

\begin_layout Standard
By Singular value decomposition, we can rewrite 
\begin_inset Formula $X$
\end_inset

 as 
\begin_inset Formula $UDV^{T}$
\end_inset

 where 
\begin_inset Formula $U$
\end_inset

 and 
\begin_inset Formula $V$
\end_inset

 are matrices with orthonormal columns and 
\begin_inset Formula $D$
\end_inset

 is diagonal matrix with non-negative diagonal elements.
 Let 
\begin_inset Formula $X=UDV^{T}$
\end_inset

 and plug it into 
\begin_inset Formula $X^{T}X$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
X^{T}X & = & (UDV^{T})^{T}UDV^{T}\\
 & = & VD^{T}U^{T}UDV^{T}\\
\mbox{(orthonormal)} & = & VD^{T}DV^{T}\\
 & = & VD'V^{T}\\
\mbox{(Compare with eigenvalue decomposition)} & = & \Gamma\Lambda\Gamma^{T}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $D'$
\end_inset

 is the diagonal matrix which its diagonal elements are the square of the
 diagonal elements in 
\begin_inset Formula $D$
\end_inset

.
 By compared the last two equation, we can get the conclusion that right
 singular vectors of 
\begin_inset Formula $X$
\end_inset

 are the eigenvectors of the matrix 
\begin_inset Formula $X^{T}X$
\end_inset

 and the eigenvalues of 
\begin_inset Formula $X^{T}X$
\end_inset

 are the squares of the singular values of 
\begin_inset Formula $X$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula $3^{\circ}$
\end_inset

 
\begin_inset Formula $X^{T}X$
\end_inset

 is positive semi-definite.
\end_layout

\begin_layout Standard
By the definition, if a matrix 
\begin_inset Formula $M$
\end_inset

 is positive semi-definite, then 
\begin_inset Formula $a^{T}Ma\ge0$
\end_inset

 for non-zero vector 
\begin_inset Formula $a$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
a^{T}X^{T}Xa & = & (Xa)^{T}Xa\\
(b=Xa) & = & b^{T}b\geq0
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Since 
\begin_inset Formula $b=Xa$
\end_inset

 is also a vector, the 
\begin_inset Formula $(Xa)^{T}Xa$
\end_inset

 calculates its length, which cannot be negative.
 Therefore, 
\begin_inset Formula $X^{T}X$
\end_inset

 is positive semi-definite.
\end_layout

\begin_layout Standard
(b) If 
\begin_inset Formula $\lambda_{1}$
\end_inset

 and 
\begin_inset Formula $v_{1}$
\end_inset

 are the eigenvalue and corresponding eigenvector of 
\begin_inset Formula $X$
\end_inset

, then 
\begin_inset Formula $Xv_{1}=\lambda_{1}v_{1}$
\end_inset

.
 Now we want to compute the eigenvalue of 
\begin_inset Formula $Z=X+cI$
\end_inset

.
 We have computed the eigendecomposition of 
\begin_inset Formula $X$
\end_inset

.
 Suppose 
\begin_inset Formula $\lambda_{i}$
\end_inset

 and 
\begin_inset Formula $v_{i}$
\end_inset

 are one pair of eigenvalue and eigenvector of 
\begin_inset Formula $X$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
Zv_{i} & = & Xv_{i}+cIv_{i}\\
 & = & \lambda_{i}v_{i}+cv_{i}\\
 & = & (\lambda_{i}+c)v_{i}\\
 & = & \lambda_{i}'v_{i}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
To compute the eigenvalues of 
\begin_inset Formula $Z$
\end_inset

, we only have to add the scalar 
\begin_inset Formula $c$
\end_inset

 to each eigenvalue 
\begin_inset Formula $\lambda_{i}$
\end_inset

, which takes 
\begin_inset Formula $O(n)$
\end_inset

 additions.
\end_layout

\end_body
\end_document
