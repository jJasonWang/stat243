#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\use_default_options true
\begin_modules
knitr
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 3cm
\topmargin 2.54cm
\rightmargin 3cm
\bottommargin 2.54cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
STAT243 Problem Set1
\end_layout

\begin_layout Author
Name: Chih Hui Wang SID: 26955255
\end_layout

\begin_layout Date
September 5, 2015
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<setup, include=FALSE>>=
\end_layout

\begin_layout Plain Layout

knitr::opts_chunk$set(fig.width = 5, fig.height = 5)
\end_layout

\begin_layout Plain Layout

knitr::opts_chunk$set(fig.align='center')
\end_layout

\begin_layout Plain Layout

knitr::opts_chunk$set(comment="")
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
1.
 (a) To solve this problem, I first downloaded the file and unziped it.
 Before dividing the data into country and region, I have to observe whether
 there is any pattern I can use to extract data.
 Then, I subseted the data by two term 
\begin_inset Quotes eld
\end_inset

2005
\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset

Area Harvested
\begin_inset Quotes erd
\end_inset

 and sort by the value column to get the top five countries.
 Finally, I generalized the above process and wrote a function that can
 automatic pritn out the top five countries, once providing a year.
 
\end_layout

\begin_layout Standard
Use 
\series bold
curl
\series default
 to download the file and modifier 
\series bold
-o
\series default
 to rename the file.
 Then, rename it as apricots.zip, otherwise the name of file will be to long
 to see.
 Then, 
\series bold
unzip
\series default
 the file (use the 
\series bold
-c
\series default
 to output the file and put it into 
\series bold
apricots.csv
\series default
.)
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<download, engine='bash'>>=
\end_layout

\begin_layout Plain Layout

#Download file 
\end_layout

\begin_layout Plain Layout

curl -s "http://data.un.org/Handlers/DownloadHandler.ashx?DataFilter=itemCode:526
\end_layout

\begin_layout Plain Layout

&DataMartId=FAO&Format=csv&c=2,3,4,5,6,7&s=countryName:asc,elementCode:asc,
\end_layout

\begin_layout Plain Layout

year:desc" -osS apricots.zip 
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Unzip 
\end_layout

\begin_layout Plain Layout

unzip -c apricots.zip > apricots.csv
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
I noticed that there is a 
\begin_inset Quotes eld
\end_inset

+
\begin_inset Quotes erd
\end_inset

 in the end of first column for the region.
 Therefore, I can use 
\series bold
grep
\series default
 to pull out those line with 
\begin_inset Quotes eld
\end_inset

+
\begin_inset Quotes erd
\end_inset

 as well as without 
\begin_inset Quotes eld
\end_inset

+
\begin_inset Quotes erd
\end_inset

 with 
\series bold
-v
\series default
 in the command.
 The country-level data will have some unmeaningful row for this problem.
 I used 
\series bold
head 
\series default
and remove the line.
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<divide, engine='bash'>>=
\end_layout

\begin_layout Plain Layout

#To observe data 
\end_layout

\begin_layout Plain Layout

cat apricots.csv | head -n5
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#For region, there will be a "+" in the end of the firt column.
 
\end_layout

\begin_layout Plain Layout

grep "+" apricots.csv > regions.csv 
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#The last 7 line is unrelated, so I remove them.
 
\end_layout

\begin_layout Plain Layout

grep -v "+" apricots.csv | head -n -7 > countries.csv
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
I subsetted the data by 
\begin_inset Quotes eld
\end_inset

2005
\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset

Area Harvested
\begin_inset Quotes erd
\end_inset

.
 When subsetting by 
\begin_inset Quotes eld
\end_inset

2005
\begin_inset Quotes erd
\end_inset

, there are also some 2005 in other columns (in a format like
\begin_inset Quotes erd
\end_inset

2005.000
\begin_inset Quotes erd
\end_inset

), so I use
\series bold
 
\backslash

\begin_inset Quotes erd
\end_inset

2005
\backslash

\begin_inset Quotes erd
\end_inset


\series default
 to ensure that I pull out the correct line.
 After 
\series bold
grep
\series default
 by 
\series bold

\begin_inset Quotes eld
\end_inset

Area Harvested
\series default

\begin_inset Quotes erd
\end_inset

, I first observed the data to check whether some countries have different
 formats.
 I found that some countries will have , in their name, so we better use
 
\series bold

\begin_inset Quotes eld
\end_inset


\series default
 to delimit data.
 Then, I have to sort the data by column 12 which represents value.
 I use the 
\series bold

\begin_inset Quotes erd
\end_inset


\series default
 to delimit the data and then sort the data from big to small 
\series bold
(-r)
\series default
 by column 12 by the command 
\series bold
-k12
\series default
 with 
\series bold
-t'
\begin_inset Quotes erd
\end_inset

'
\series default
 indicating that I want to use 
\series bold

\begin_inset Quotes eld
\end_inset


\series default
 to seperate each column.
 Finally, use 
\series bold
head
\series default
 to get the top 5 countries and 
\series bold
cut
\series default
 to get the first column.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<Countries, engine='bash'>>=
\end_layout

\begin_layout Plain Layout

cut -d'"' -f2 countries.csv | uniq
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<2005, engine='bash'>>=
\end_layout

\begin_layout Plain Layout

#2005 Area Harvested 
\end_layout

\begin_layout Plain Layout

grep 
\backslash
"2005
\backslash
" countries.csv | grep "Area Harvested" | sort -nr -t'"' -k12 | head -n5
 |
\end_layout

\begin_layout Plain Layout

cut -d'"' -f2 
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<function, engine='bash'>>=
\end_layout

\begin_layout Plain Layout

#function 
\end_layout

\begin_layout Plain Layout

function rankAH() { 
\end_layout

\begin_layout Plain Layout

	grep 
\backslash
"$1
\backslash
" countries.csv | grep "Area Harvested" | sort -nr -t'"' -k12 | head -n5
 |
\end_layout

\begin_layout Plain Layout

cut -d'"' -f2  
\end_layout

\begin_layout Plain Layout

} 
\end_layout

\begin_layout Plain Layout

#1965, 1975, 1985, 1995
\end_layout

\begin_layout Plain Layout

echo 1965
\end_layout

\begin_layout Plain Layout

rankAH 1965 
\end_layout

\begin_layout Plain Layout

echo 1975
\end_layout

\begin_layout Plain Layout

rankAH 1975 
\end_layout

\begin_layout Plain Layout

echo 1985
\end_layout

\begin_layout Plain Layout

rankAH 1985
\end_layout

\begin_layout Plain Layout

echo 1995
\end_layout

\begin_layout Plain Layout

rankAH 1995
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
(b) The parameter of the function is the itemcode.
 I used
\series bold
 curl
\series default
 the first step in (a) to download data and rename it.
 Then, when 
\series bold
unzip
\series default
 the file, I set a modifier
\series bold
 -p
\series default
 which can directly print out data and the result can be use by other operation
 such as 
\series bold
head
\series default
, 
\series bold
sort
\series default
.
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<function1, engine='bash'>>=
\end_layout

\begin_layout Plain Layout

function dldata() { 	
\end_layout

\begin_layout Plain Layout

	curl -s "http://data.un.org/Handlers/DownloadHandler.ashx?DataFilter=itemCode:$1
\end_layout

\begin_layout Plain Layout

&DataMartId=FAO&Format=csv&c=2,3,4,5,6,7&s=countryName:asc,elementCode:asc,
\end_layout

\begin_layout Plain Layout

year:desc" -o $1.zip 
\end_layout

\begin_layout Plain Layout

	unzip -p $1.zip 
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Test
\end_layout

\begin_layout Plain Layout

#first 5 rows 
\end_layout

\begin_layout Plain Layout

dldata 572 | head -n5
\end_layout

\begin_layout Plain Layout

#sort by value
\end_layout

\begin_layout Plain Layout

dldata 572 | head -n5 | sed 's/"//g' | sort -nr -t',' -k6
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
(c) To deal with the problem, first I have to find the table of item and
 its name, so I go to the website (http://faostat.fao.org/site/384/default.aspx).
 I used wget to get the html and then see whether any pattern I can utilize.
 I found that 
\begin_inset Quotes eld
\end_inset

</td><td>
\begin_inset Quotes erd
\end_inset

 can help me to pull out the item name and code.
 I used sed to substite the < to > and then I can easily delimit the data
 by >.
 The item code is located at 7 column and the name is located at 15 if using
 the > as a delimiter.
 Finally, I wrote a function call Itemname.
 Once the user input the name, then the function will use the 
\series bold
grep
\series default
 and 
\series bold
cut
\series default
 to get the correct itemcode and then output the data by the function 
\series bold
dldata 
\series default
in (b).
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<Itemcode, engine='bash'>>=
\end_layout

\begin_layout Plain Layout

#Match file preparation
\end_layout

\begin_layout Plain Layout

curl -s "http://faostat.fao.org/site/384/default.aspx" > table.html 
\end_layout

\begin_layout Plain Layout

grep "</td><td>" table.html | sed 's/</>/g' | cut -d'>' -f7,15 > code.txt
\end_layout

\begin_layout Plain Layout

#function
\end_layout

\begin_layout Plain Layout

function dldataName() {
\end_layout

\begin_layout Plain Layout

	itemcode=$(grep $1 code.txt | cut -d'>' -f1)
\end_layout

\begin_layout Plain Layout

	curl -s "http://data.un.org/Handlers/DownloadHandler.ashx?DataFilter=itemCode:$ite
mcode
\end_layout

\begin_layout Plain Layout

&DataMartId=FAO&Format=csv&c=2,3,4,5,6,7&s=countryName:asc,elementCode:asc,
\end_layout

\begin_layout Plain Layout

year:desc" -o $1.zip
\end_layout

\begin_layout Plain Layout

	unzip -p $1.zip 
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

#Example
\end_layout

\begin_layout Plain Layout

dldataName Apricots | head -n5
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
2.
 To address the problem, I think that I have to examine the source code
 of the website, find out those line with 
\series bold

\begin_inset Quotes eld
\end_inset

.txt
\begin_inset Quotes erd
\end_inset


\series default
 and then detect any pattern I can utilize to get the whole name of txt
 file.
 After that I can use a for loop to download those files.
 In the for loop, I can write a command to print out which file is downloading.
\end_layout

\begin_layout Standard
I use 
\series bold
wget
\series default
 to get the html code.
 
\series bold
-O - 
\series default
is to get the standard out which I can store in a txt file, called 
\series bold
allhtml.txt
\series default
.
 When I saw the output of 
\series bold
grep 
\begin_inset Quotes eld
\end_inset

.txt
\begin_inset Quotes erd
\end_inset

 allhtml.txt
\series default
, I found that the file name is between two 
\series bold

\begin_inset Quotes eld
\end_inset


\series default
.
 Therefore, I can use 
\series bold

\begin_inset Quotes eld
\end_inset


\series default
 to delimit the data and get out the name by command 
\series bold
cut
\series default
.
 I stored the output into a variable called 
\series bold
dowload
\series default
.
 and then write a for loop to download files as well as print out which
 file I am downloading now.
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<function2, engine='bash'>>=
\end_layout

\begin_layout Plain Layout

#Get html
\end_layout

\begin_layout Plain Layout

curl -s "http://www1.ncdc.noaa.gov/pub/data/ghcn/daily/" > allhtml.txt
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#See pattern
\end_layout

\begin_layout Plain Layout

grep ".txt" allhtml.txt | head -n1
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Make a variable 
\end_layout

\begin_layout Plain Layout

download=$(grep ".txt" allhtml.txt | cut -d'"' -f8)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#For loop
\end_layout

\begin_layout Plain Layout

for file in $download 	
\end_layout

\begin_layout Plain Layout

do  echo "Download $file now" 	
\end_layout

\begin_layout Plain Layout

	curl -s "http://www1.ncdc.noaa.gov/pub/data/ghcn/daily/$file" -o $file
\end_layout

\begin_layout Plain Layout

done
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset

The height of the water level in Lake Huron fluctuates over time.
 Here I ’analyze’ the variation using R.
 I show a histogram of the lake levels for the period 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
Sexpr{attributes(LakeHuron)$tsp[1]}
\end_layout

\end_inset

 to 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
Sexpr{attributes(LakeHuron)$tsp[2]}
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<r>>=
\end_layout

\begin_layout Plain Layout

hist(LakeHuron) 
\end_layout

\begin_layout Plain Layout

lowHi <- c(which.min(LakeHuron), which.max(LakeHuron))
\end_layout

\begin_layout Plain Layout

attributes(LakeHuron)$tsp[1] - 1 + lowHi
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_body
\end_document
